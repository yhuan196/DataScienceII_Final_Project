---
title: "Data science final guideline"
author: "Yi Huang, Yuchen Zhang, Shun Xie"
date: "2023-04-28"
output: 
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
  fontsize: 10pt
  geometry: margin=0.5in
  header-includes:
    -\usepackage{fancyhdr}
    -\usepackage{lipsum}
    -\pagestyle{fancy}
    -\fancyhead[R]{\thepage}
    -\fancypagestyle{plain}{\pagestyle{fancy}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.align = "center",
                      fig.width = 8, 
                      fig.height = 6,
                      out.width = "90%")
```

# Final Project


## Deliverables and deadlines
Due: May 10 by 11:59pm\
Each team is required to submit one report.


## Dataset

Please merge the midterm project datasets from two team members, and keep only the unique observations. If there are three team members, you can decide which two datasets to merge. 


## Background

To gain a better understanding of the factors that predict recovery time from COVID-19 illness, a study was designed to combine three existing cohort studies that have been tracking participants for several years. The study collects recovery information through questionnaires and medical records, and leverages existing data on personal characteristics prior to the pandemic. The ultimate goal is to develop a prediction model for recovery time and identify important risk factors for long recovery time.


## Data

recovery.RData 

The dataset in "recovery.RData" consists of 10000 participants. In your analysis, please draw a random sample of 2000 participants using the following R code:

set.seed([last four digits of your UNI]) 

dat <- dat[sample(1:10000, 2000),]

The resulting dat object will contain a random sample of 2000 participants that you can use for your analysis.


## Here is a description of each variable:

Variable Description

- ID (id) :Participant ID

- Gender (gender): 1 = Male, 0 = Female

- Race/ethnicity (race): 1 = White, 2 = Asian, 3 = Black, 4 = Hispanic

- Smoking (smoking): Smoking status; 0 = Never smoked, 1 = Former smoker, 2 = Current smoker

- Height (height): Height (in centimeters)

- Weight (weight): Weight (in kilograms)

- BMI (bmi): Body Mass Index; BMI = weight (in kilograms) / height (in meters) squared

- Hypertension (hypertension): 0 = No, 1 = Yes

- Diabetes (diabetes): 0 = No, 1 = Yes

- Systolic blood pressure (SBP): Systolic blood pressure (in mm/Hg)

- LDL cholesterol (LDL): LDL (low-density lipoprotein) cholesterol (in mg/dL)

- Vaccination status at the time of infection (vaccine): 0 = Not vaccinated, 1 = Vaccinated

- Severity of COVID-19 infection (severity): 0 = Not severe, 1= Severe

- Study (study): The study (A/B/C) that the participant belongs to

- Time to recovery (tt_recovery_time): Time from COVID-19 infection to recovery in days
 

## Report

Your report should be no more than five pages, excluding figures and tables. The total number of figures and tables should not exceed 8. You can submit an Appendix if you would like to include more details for modeling tuning.

For the primary analysis on time to recovery, you may revise your midterm report and incorporate new findings from the methods introduced in the second half of the semester.

As a secondary analysis, please consider time to recovery as a binary outcome (>30 days vs. <= 30 days) and develop a prediction model for this binary outcome.

 
## Note

Similar to the midterm project report, your report should include the following sections: exploratory analysis and data visualization, model training, results, and conclusions. 


```{r, message=FALSE, warning=FALSE}
library(caret)
library(corrplot)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(ISLR)
library(glmnet)
library(mgcv)
library(nlme)
library(earth)
library(vip)
```

## Introduction
```{r}
#load data
load("data/recovery.RData")

#get data from 2 team members uni
set.seed(3554)
dat1 <- dat[sample(1:10000, 2000),]
set.seed(4437)
dat2 <- dat[sample(1:10000, 2000),]

#combine the data and discard duplicates
dat_temp <- rbind(dat1, dat2)
dat <- dat_temp[!duplicated(dat_temp$id),]

#dat is now the final data and it has the length as following:
length(dat$id)

# save(dat, file = "data/covid_recovery.RData")
```


```{r}
# data manipulation
data = 
  dat %>% 
  mutate(study = factor(dat$study),
         gender = factor(dat$gender),
         hypertension = factor(dat$hypertension),
         diabetes = factor(dat$diabetes),
         vaccine = factor(dat$vaccine),
         severity = factor(dat$severity)) %>% 
  dplyr::select(-id)
head(data)

 
#Split data into 80-20, using the third member's uni
set.seed(8)
indexTrain <- createDataPartition(y = data$recovery_time, p = 0.8, list = FALSE)

# training data
train_data <- data[indexTrain,]
train_x <- data[indexTrain,]
train_y <- data$recovery_time[indexTrain]

# test data
test_data <- data[-indexTrain,]
test_x <- data[-indexTrain,]
test_y <- data$recovery_time[-indexTrain]
```



## Exploratory Data Analysis on train data

```{r}
#continuous
ggplot(train_data, aes(x = age))+geom_density()+labs(title="Distribution for age")
ggplot(train_data, aes(x = height))+geom_density()+labs(title="Distribution for height")
ggplot(train_data, aes(x = weight))+geom_density()+labs(title="Distribution for weight")
ggplot(train_data, aes(x = bmi))+geom_density()+labs(title="Distribution for bmi")
ggplot(train_data, aes(x = SBP))+geom_density()+labs(title="Distribution for SBP")
ggplot(train_data, aes(x = LDL))+geom_density()+labs(title="Distribution for LDL")
ggplot(train_data, aes(x = recovery_time))+geom_density()+labs(title="Distribution for recovery_time")


#discrete
ggplot(train_data) + geom_bar(aes(x=gender))+labs(title="Bar plot for different gender")
ggplot(train_data) + geom_bar(aes(x=race))+labs(title="Bar plot for different race")
ggplot(train_data) + geom_bar(aes(x=smoking))+labs(title="Bar plot for different smoking")
ggplot(train_data) + geom_bar(aes(x=hypertension))+labs(title="Bar plot for different hypertension")
ggplot(train_data) + geom_bar(aes(x=diabetes))+labs(title="Bar plot for different diabetes")
ggplot(train_data) + geom_bar(aes(x=vaccine))+labs(title="Bar plot for different vaccine")
ggplot(train_data) + geom_bar(aes(x=severity))+labs(title="Bar plot for different severity")
ggplot(train_data) + geom_bar(aes(x=study))+labs(title="Bar plot for different study")


num_df <- 
  train_data %>% 
  dplyr::select(age, height, weight, bmi, SBP, LDL, recovery_time) 


# calulate the correlations
res <- cor(num_df, use="complete.obs")

corrplot(res, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

```


#ENet
```{r}
# matrix of predictors
x <- model.matrix(recovery_time~.,data)[,-1]

# vector of response
y <- data$recovery_time


# repeated 10-fold cv
ctrl <- trainControl(method = "cv",
                     number = 10)

```



```{r}

#tuning glmnet alpha 0 and 0.05 have large RMSE. So alpha start from 0.1
set.seed(8)
enet.fit.min <- train(train_x, train_y,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0.1, 1, length = 21), 
                                         lambda = exp(seq(-10, -5, length = 100))),
                  trControl = ctrl)
enet.fit.min$bestTune
plot(enet.fit.min)


# view performance on the test set (RMSE)
enet_test_pred <- predict(enet.fit.min, newdata = test_x) # test dataset
enet_test_rmse <- sqrt(mean((enet_test_pred - test_y)^2))
sprintf("test error for enet is: %.3f",enet_test_rmse)

```


#class

```{r}
#consider time to recovery as a binary outcome (>30 days vs. <= 30 days) and develop a prediction model for this binary outcome.
train_class = 
  train_data %>% 
  mutate(recovery_time = ifelse(recovery_time>30, "long", "short"))

test_class = 
  test_data %>% 
  mutate(recovery_time = ifelse(recovery_time>30, "long", "short"))

# matrix of predictors
x_train_class <- model.matrix(recovery_time~.,train_class)[,-1]
# vector of response
y_train_class <- train_class$recovery_time


# matrix of predictors
x_test_class <- model.matrix(recovery_time~.,test_class)[,-1]
# vector of response
y_test_class <- train_class$recovery_time


# ctrl for class
ctrl_class <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
```

### Logistic enet

```{r}
glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 21),
                        .lambda = exp(seq(-12, -7, length = 50)))
set.seed(8)
model.glmn <- train(x = x_train_class,
                    y = y_train_class,
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    metric = "ROC",
                    trControl = ctrl_class)

model.glmn$bestTune

myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(model.glmn, par.settings = myPar, xTrans = function(x) log(x))


# view performance on the test set (accuracy)
glmn_class_test_pred <- predict(model.glmn, newdata=x_test_class) # test dataset
glmn_class_test_acc <- sum(glmn_class_test_pred==y_test_class)/length(y_test_class)
sprintf("test error for penalized logistic is: %.3f",1-glmn_class_test_acc)


```


```{r}
glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 21),
                        .lambda = exp(seq(-12, -7, length = 50)))
set.seed(1)
model.glmn <- train(x = x_train_class,
                    y = y_test_class,
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    metric = "ROC",
                    trControl = ctrl_class)

model.glmn$bestTune

myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(model.glmn, par.settings = myPar, xTrans = function(x) log(x))
```

#### Gam

```{r}
# gam
set.seed(8)
model.gam <- train(x = x_train_class,
                   y = y_train_class,
                   method = "gam",
                   tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE)),
                   metric = "ROC",
                   trControl = ctrl_class)

model.gam$bestTune
model.gam$finalModel

#discover bmi and recovery time
plot(model.gam$finalModel, select = 4)

#train error
train.pred.gam <- predict(model.gam, newdata = x_train_class)
train.error.gam = 1-sum(train_class$recovery_time == train.pred.gam)/length(train_data$recovery_time)
sprintf("The train error for GAM is %.3f", train.error.gam)

#test error
test.pred.gam <- predict(model.gam, newdata = x_test_class)
test.error.gam = 1-sum(test_class$recovery_time == test.pred.gam)/length(test_class$recovery_time)
sprintf("The test error for GAM is %.3f", test.error.gam)
```

#### Linear SVM

```{r}
# parallel computing
no_cores <- detectCores() - 1
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)

# kernlab
set.seed(8)
svml.fit <- train(recovery_time ~ . , 
                  data = train_class, 
                  method = "svmLinear",
                  tuneGrid = data.frame(C = exp(seq(-4,9,len=30))),
                  trControl = ctrl)

plot(svml.fit, highlight = TRUE, xTrans = log)

stopCluster(cl)
registerDoSEQ()

#train error
train.pred.svml <- predict(svml.fit, newdata = train_class)
train.error.svml = 1-sum(train_class$recovery_time == train.pred.svml)/length(train_data$recovery_time)
sprintf("The train error for Support vector classifier is %.3f", train.error.svml)

#test error
test.pred.svml <- predict(svml.fit, newdata = test_class)
test.error.svml = 1-sum(test_class$recovery_time == test.pred.svml)/length(test_class$recovery_time)
sprintf("The test error for Support vector classifier is %.3f", test.error.svml)
```




```{r}
# parallel computing
no_cores <- detectCores() - 1
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)

# kernlab
set.seed(8)
svml.fit <- train(recovery_time ~ . , 
                  data = train_class, 
                  method = "svmLinear",
                  tuneGrid = data.frame(C = exp(seq(-10,-2,len=30))),
                  trControl = ctrl)

plot(svml.fit, highlight = TRUE, xTrans = log)

stopCluster(cl)
registerDoSEQ()
```


set.seed(8)
svml.fit <- train(recovery_time ~ . , 
                  data = train_class, 
                  method = "svmLinear",
                  tuneGrid = data.frame(C = exp(seq(7,10,len=10))),
                  trControl = ctrl)

plot(svml.fit, highlight = TRUE, xTrans = log)






```{r}
svmr.grid <- expand.grid(C = exp(seq(-4,3,len=20)),
                         sigma = exp(seq(-10,-2,len=10)))

# parallel computing
no_cores <- detectCores() - 1
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)

# tunes over both cost and sigma
set.seed(8)             
svmr.fit <- train(recovery_time ~ . , 
                  data = train_class,
                  method = "svmRadialSigma",
                  tuneGrid = svmr.grid,
                  trControl = ctrl)

stopCluster(cl)
registerDoSEQ()



myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(svmr.fit, highlight = TRUE, par.settings = myPar)

svmr.fit$bestTune


#train error
train.pred.svmr <- predict(svmr.fit, newdata = train_class)
train.error.svmr = 1-sum(train_class$recovery_time == train.pred.svmr)/length(train_class$recovery_time)
sprintf("The train error for Support vector Machine with radial kernel is %.3f", train.error.svmr)

#test error
test.pred.svmr <- predict(svmr.fit, newdata = test_class)
test.error.svmr = 1-sum(test_class$recovery_time == test.pred.svmr)/length(test_class$recovery_time)
sprintf("The test error for Support vector Machine with radial kernel is %.3f", test.error.svmr)
```

After tuning, the cost in this range achieves local maximum accuracy. The value is not on the boundary, hence the local maximum accuracy is achieved. It takes a long time (aprox 30 min) to run so it may be hard to refine into a smaller grid.




### Final Model


#### GAM

```{r}
#Formula 
summary(model.gam)

#degrees of freedom
model.gam$finalModel

#can also visualize the pairwise relation:
vis.gam(model.gam$finalModel, view=c("age","pregnant"), color = "topo")
vis.gam(model.gam$finalModel, view=c("age","triceps"), color = "topo")
vis.gam(model.gam$finalModel, view=c("age","glucose"), color = "topo")
vis.gam(model.gam$finalModel, view=c("age","pedigree"), color = "topo")

```

